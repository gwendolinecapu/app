import { IImageProvider } from '../interfaces/IImageProvider';

export class OpenAIProvider implements IImageProvider {
    private apiKey: string;
    private model: string;

    constructor(apiKey: string, model: string = "dall-e-3") {
        this.apiKey = apiKey;
        this.model = model;
    }

    async generateInfoImage(prompt: string, options?: any): Promise<any> {
        // Map abstract quality to OpenAI specific quality for gpt-image-1.5
        let targetQuality = 'standard';
        let useResponsesApi = false;

        if (this.model.includes('gpt-image-1.5')) {
            useResponsesApi = true;
            if (options?.quality === 'eco')
                targetQuality = 'low';
            else if (options?.quality === 'std')
                targetQuality = 'medium';
            else if (options?.quality === 'high')
                targetQuality = 'high';
        }
        else {
            // Fallback for DALL-E 3
            targetQuality = options?.quality === 'high' ? 'hd' : 'standard';
        }

        // GPT-1.5 with Reference Images (Responses API)
        if (useResponsesApi && options?.referenceImages && options.referenceImages.length > 0) {
            const inputContent: any[] = [{ type: "input_text", text: prompt }];

            // Add reference images (max 5 for high fidelity)
            options.referenceImages.slice(0, 5).forEach((base64: string) => {
                inputContent.push({
                    type: "input_image",
                    image_url: `data:image/jpeg;base64,${base64}`
                });
            });

            const payload = {
                model: this.model,
                input: [{
                    role: "user",
                    content: inputContent
                }],
                tools: [{
                    type: "image_generation",
                    quality: targetQuality,
                    input_fidelity: "high",
                    action: "generate"
                }]
            };

            const response = await fetch("https://api.openai.com/v1/responses", {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${this.apiKey}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(payload)
            });

            if (!response.ok) {
                const errText = await response.text();
                throw new Error(`OpenAI Responses API Error (${response.status}): ${errText}`);
            }

            const result = await response.json();
            // Extract image from output
            const imageGenerations = result.output.filter((o: any) => o.type === "image_generation_call");

            if (!imageGenerations.length)
                throw new Error("No image generated by Responses API");

            return imageGenerations.map((g: any) => Buffer.from(g.result, 'base64'));
        }

        // Standard Image API (DALL-E 3 or GPT-1.5 without refs)
        const size = "1024x1024";
        const payload = {
            model: this.model,
            prompt: prompt,
            n: 1,
            size: size,
            quality: targetQuality,
            response_format: "b64_json"
        };

        const response = await fetch("https://api.openai.com/v1/images/generations", {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${this.apiKey}`,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify(payload)
        });

        if (!response.ok) {
            const errText = await response.text();
            throw new Error(`OpenAI Error (${response.status}): ${errText}`);
        }

        const result = await response.json();
        const buffers = result.data.map((d: any) => Buffer.from(d.b64_json, 'base64'));
        return buffers;
    }
}
